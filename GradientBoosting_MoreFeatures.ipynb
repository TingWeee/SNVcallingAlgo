{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place the python file in the same folder containing all the real1, real2_part1, ... folders\n",
    "\n",
    "def parse_to_df(folder='test', features='*', algos=['freebayes', 'mutect2', 'vardict', 'varscan']):\n",
    "    '''\n",
    "    reads all vcf.gz files corresponding to algos in the specified folder with the specified list of features\n",
    "    and combines the read files into one dataframe with (CHROM, POS, REF) as index.\n",
    "    '''\n",
    "    if folder == 'test':\n",
    "        dfs = [allel.vcf_to_dataframe(f'{folder}/{i}.vcf.gz', fields = features) for i in algos]\n",
    "    else:\n",
    "        dfs = [allel.vcf_to_dataframe(f'{folder}/{folder}-{i}.vcf.gz', fields = features) for i in algos]\n",
    "    algo_dicts = dict(zip(algos, dfs))\n",
    "    \n",
    "    #some manipulations\n",
    "    for i in algo_dicts:\n",
    "        algo_dicts[i].set_index(keys=['CHROM', 'POS', 'REF'], inplace = True) #will be use as keys for later merging\n",
    "        algo_dicts[i] = algo_dicts[i][algo_dicts[i]['is_snp']]    #obtain only SNPs\n",
    "        algo_dicts[i].columns = [j + '_' + i for j in algo_dicts[i].columns]\n",
    "\n",
    "    #combining the dfs\n",
    "    edited_dfs = [algo_dicts[i] for i in algos]\n",
    "\n",
    "    merged = reduce(lambda left, right: pd.merge(left, right,\n",
    "                                            how = 'outer',\n",
    "                                            left_index=True, right_index=True,\n",
    "                                            suffixes = ('', '')), edited_dfs)\n",
    "\n",
    "    merged.columns = sorted(merged.columns)\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_with_drop_na(folder='test', features='*', drop_threshold=50):\n",
    "    \n",
    "    # Parse VCF files to DataFrames\n",
    "    algos = ['freebayes', 'mutect2', 'vardict', 'varscan']\n",
    "    if folder == 'test':\n",
    "        dfs = [allel.vcf_to_dataframe(f'{folder}/{i}.vcf.gz', fields=features) for i in algos]\n",
    "    else:\n",
    "        dfs = [allel.vcf_to_dataframe(f'{folder}/{folder}-{i}.vcf.gz', fields=features) for i in algos]\n",
    "    algo_dicts = dict(zip(algos, dfs)) # a dictionary of key = algo, value = algo results\n",
    "    \n",
    "    \n",
    "    # Rename columns\n",
    "    keep_same = {'CHROM', 'POS'}\n",
    "    for i in algos:\n",
    "        algo_dicts[i] = algo_dicts[i][algo_dicts[i]['is_snp']] # obtain only SNPs\n",
    "        algo_dicts[i].columns = ['{}{}'.format(c, '' if c in keep_same else '_' + i) for c in algo_dicts[i].columns]\n",
    "        \n",
    "        \n",
    "    # Drop columns with >50% missing values\n",
    "    for alg in algo_dicts:\n",
    "        features_to_drop = []\n",
    "        for feature in algo_dicts[alg].columns:\n",
    "            \n",
    "            # Calculate percentage of rows with missing values\n",
    "            n_miss = algo_dicts[alg][[feature]].isnull().sum() \n",
    "            perc = n_miss / algo_dicts[alg].shape[0] * 100\n",
    "            \n",
    "            # If >50% of values are missing, drop feature\n",
    "            if (float)(perc) > drop_threshold:\n",
    "                features_to_drop.append(feature)\n",
    "\n",
    "        algo_dicts[alg].drop(labels = features_to_drop, axis=1, inplace=True)\n",
    "        \n",
    "        \n",
    "    # Merge DataFrames from diff algos\n",
    "    edited_dfs = [algo_dicts[i] for i in algos]\n",
    "    merged = reduce(lambda left, right: pd.merge(left, right, on =['CHROM', 'POS'],\n",
    "                                                how = 'outer', suffixes = ('', '')), edited_dfs)\n",
    "    \n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes some time to run\n",
    "\n",
    "target_folder = 'syn1'\n",
    "\n",
    "df = parse_with_drop_na(folder=target_folder)\n",
    "df.to_csv(f'{target_folder}_merged_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meanings of VCF file headers\n",
    "To help with feature choice\n",
    "\n",
    "#### Freebayes\n",
    "* FILTER=<ID=PASS,Description=\"All filters passed\">\n",
    "* FILTER=<ID=REJECT,Description=\"Not somatic due to normal call frequency or phred likelihoods: tumor: 35, normal 35.\">\n",
    "* FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Number of observation for each allele\">\n",
    "* FORMAT=<ID=AO,Number=A,Type=Integer,Description=\"Alternate allele observation count\">\n",
    "* FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read Depth\">\n",
    "* FORMAT=<ID=GL,Number=G,Type=Float,Description=\"Genotype Likelihood, log10-scaled likelihoods of the data given the called genotype for each possible genotype generated from the reference and alternate alleles given the sample ploidy\">\n",
    "* FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality, the Phred-scaled marginal (or unconditional) probability of the called genotype\">\n",
    "* FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
    "* FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=\"Minimum depth in gVCF output block.\">\n",
    "* FORMAT=<ID=PL,Number=G,Type=Integer,Description=\"Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification\">\n",
    "* FORMAT=<ID=QA,Number=A,Type=Integer,Description=\"Sum of quality of the alternate observations\">\n",
    "* FORMAT=<ID=QR,Number=1,Type=Integer,Description=\"Sum of quality of the reference observations\">\n",
    "* FORMAT=<ID=RO,Number=1,Type=Integer,Description=\"Reference allele observation count\">\n",
    "* INFO=<ID=AB,Number=A,Type=Float,Description=\"Allele balance at heterozygous sites: a number between 0 and 1 representing the ratio of reads showing the reference allele to all reads, considering only reads from individuals called as heterozygous\">\n",
    "* INFO=<ID=ABP,Number=A,Type=Float,Description=\"Allele balance probability at heterozygous sites: Phred-scaled upper-bounds estimate of the probability of observing the deviation between ABR and ABA given E(ABR/ABA) ~ 0.5, derived using Hoeffding's inequality\">\n",
    "* INFO=<ID=AC,Number=A,Type=Integer,Description=\"Total number of alternate alleles in called genotypes\">\n",
    "* INFO=<ID=AF,Number=A,Type=Float,Description=\"Estimated allele frequency in the range (0,1]\">\n",
    "* INFO=<ID=AN,Number=1,Type=Integer,Description=\"Total number of alleles in called genotypes\">\n",
    "* INFO=<ID=AO,Number=A,Type=Integer,Description=\"Count of full observations of this alternate haplotype.\">\n",
    "* INFO=<ID=CIGAR,Number=A,Type=String,Description=\"The extended CIGAR representation of each alternate allele, with the exception that '=' is replaced by 'M' to ease VCF parsing.  Note that INDEL alleles do not have the first matched base (which is provided by default, per the spec) referred to by the CIGAR.\">\n",
    "* INFO=<ID=DECOMPOSED,Number=0,Type=Flag,Description=\"The allele was parsed using vcfallelicprimitives.\">\n",
    "* INFO=<ID=DP,Number=1,Type=Integer,Description=\"Total read depth at the locus\">\n",
    "* INFO=<ID=DPB,Number=1,Type=Float,Description=\"Total read depth per bp at the locus; bases in reads overlapping / bases in haplotype\">\n",
    "* INFO=<ID=DPRA,Number=A,Type=Float,Description=\"Alternate allele depth ratio.  Ratio between depth in samples with each called alternate allele and those without.\">\n",
    "* INFO=<ID=END,Number=1,Type=Integer,Description=\"Last position (inclusive) in gVCF output record.\">\n",
    "* INFO=<ID=EPP,Number=A,Type=Float,Description=\"End Placement Probability: Phred-scaled upper-bounds estimate of the probability of observing the deviation between EL and ER given E(EL/ER) ~ 0.5, derived using Hoeffding's inequality\">\n",
    "* INFO=<ID=EPPR,Number=1,Type=Float,Description=\"End Placement Probability for reference observations: Phred-scaled upper-bounds estimate of the probability of observing the deviation between EL and ER given E(EL/ER) ~ 0.5, derived using Hoeffding's inequality\">\n",
    "* INFO=<ID=GTI,Number=1,Type=Integer,Description=\"Number of genotyping iterations required to reach convergence or bailout.\">\n",
    "* INFO=<ID=LEN,Number=A,Type=Integer,Description=\"allele length\">\n",
    "* INFO=<ID=MEANALT,Number=A,Type=Float,Description=\"Mean number of unique non-reference allele observations per sample with the corresponding alternate alleles.\">\n",
    "* INFO=<ID=MIN_DP,Number=1,Type=Integer,Description=\"Minimum depth in gVCF output block.\">\n",
    "* INFO=<ID=MQM,Number=A,Type=Float,Description=\"Mean mapping quality of observed alternate alleles\">\n",
    "* INFO=<ID=MQMR,Number=1,Type=Float,Description=\"Mean mapping quality of observed reference alleles\">\n",
    "* INFO=<ID=NS,Number=1,Type=Integer,Description=\"Number of samples with data\">\n",
    "* INFO=<ID=NUMALT,Number=1,Type=Integer,Description=\"Number of unique non-reference alleles in called genotypes at this position.\">\n",
    "* INFO=<ID=ODDS,Number=1,Type=Float,Description=\"The log odds ratio of the best genotype combination to the second-best.\">\n",
    "* INFO=<ID=OLD_VARIANT,Number=.,Type=String,Description=\"Original chr:pos:ref:alt encoding\">\n",
    "* INFO=<ID=PAIRED,Number=A,Type=Float,Description=\"Proportion of observed alternate alleles which are supported by properly paired read fragments\">\n",
    "* INFO=<ID=PAIREDR,Number=1,Type=Float,Description=\"Proportion of observed reference alleles which are supported by properly paired read fragments\">\n",
    "* INFO=<ID=PAO,Number=A,Type=Float,Description=\"Alternate allele observations, with partial observations recorded fractionally\">\n",
    "* INFO=<ID=PQA,Number=A,Type=Float,Description=\"Alternate allele quality sum in phred for partial observations\">\n",
    "* INFO=<ID=PQR,Number=1,Type=Float,Description=\"Reference allele quality sum in phred for partial observations\">\n",
    "* INFO=<ID=PRO,Number=1,Type=Float,Description=\"Reference allele observation count, with partial observations recorded fractionally\">\n",
    "* INFO=<ID=QA,Number=A,Type=Integer,Description=\"Alternate allele quality sum in phred\">\n",
    "* INFO=<ID=QR,Number=1,Type=Integer,Description=\"Reference allele quality sum in phred\">\n",
    "* INFO=<ID=RO,Number=1,Type=Integer,Description=\"Count of full observations of the reference haplotype.\">\n",
    "* INFO=<ID=RPL,Number=A,Type=Float,Description=\"Reads Placed Left: number of reads supporting the alternate balanced to the left (5') of the alternate allele\">\n",
    "* INFO=<ID=RPP,Number=A,Type=Float,Description=\"Read Placement Probability: Phred-scaled upper-bounds estimate of the probability of observing the deviation between RPL and RPR given E(RPL/RPR) ~ 0.5, derived using Hoeffding's inequality\">\n",
    "* INFO=<ID=RPPR,Number=1,Type=Float,Description=\"Read Placement Probability for reference observations: Phred-scaled upper-bounds estimate of the probability of observing the deviation between RPL and RPR given E(RPL/RPR) ~ 0.5, derived using Hoeffding's inequality\">\n",
    "* INFO=<ID=RPR,Number=A,Type=Float,Description=\"Reads Placed Right: number of reads supporting the alternate balanced to the right (3') of the alternate allele\">\n",
    "* INFO=<ID=RUN,Number=A,Type=Integer,Description=\"Run length: the number of consecutive repeats of the alternate allele in the reference genome\">\n",
    "* INFO=<ID=SAF,Number=A,Type=Integer,Description=\"Number of alternate observations on the forward strand\">\n",
    "* INFO=<ID=SAP,Number=A,Type=Float,Description=\"Strand balance probability for the alternate allele: Phred-scaled upper-bounds estimate of the probability of observing the deviation between SAF and SAR given E(SAF/SAR) ~ 0.5, derived using Hoeffding's inequality\">\n",
    "* INFO=<ID=SAR,Number=A,Type=Integer,Description=\"Number of alternate observations on the reverse strand\">\n",
    "* INFO=<ID=SOMATIC,Number=0,Type=Flag,Description=\"Somatic event\">\n",
    "* INFO=<ID=SRF,Number=1,Type=Integer,Description=\"Number of reference observations on the forward strand\">\n",
    "* INFO=<ID=SRP,Number=1,Type=Float,Description=\"Strand balance probability for the reference allele: Phred-scaled upper-bounds estimate of the probability of observing the deviation between SRF and SRR given E(SRF/SRR) ~ 0.5, derived using Hoeffding's inequality\">\n",
    "* INFO=<ID=SRR,Number=1,Type=Integer,Description=\"Number of reference observations on the reverse strand\">\n",
    "* INFO=<ID=TYPE,Number=A,Type=String,Description=\"The type of allele, either snp, mnp, ins, del, or complex.\">\n",
    "* INFO=<ID=technology.illumina,Number=A,Type=Float,Description=\"Fraction of observations supporting the alternate observed in reads from illumina\">\n",
    "\n",
    "#### Mutect2\n",
    "* FILTER=<ID=PASS,Description=\"All filters passed\">\n",
    "* FILTER=<ID=MinAF,Description=\"Allele frequency is lower than 10.0% (default threshold in bcbio; override with min_allele_fraction in the algorithm section)\">\n",
    "* FILTER=<ID=alt_allele_in_normal,Description=\"Evidence seen in the normal sample\">\n",
    "* FILTER=<ID=clustered_events,Description=\"Clustered events observed in the tumor\">\n",
    "* FILTER=<ID=clustered_read_position,Description=\"Evidence for somatic variant clusters near the ends of reads\">\n",
    "* FILTER=<ID=germline_risk,Description=\"Evidence indicates this site is germline, not somatic\">\n",
    "* FILTER=<ID=homologous_mapping_event,Description=\"More than three events were observed in the tumor\">\n",
    "* FILTER=<ID=multi_event_alt_allele_in_normal,Description=\"Multiple events observed in tumor and normal\">\n",
    "* FILTER=<ID=panel_of_normals,Description=\"Seen in at least 2 samples in the panel of normals\">\n",
    "* FILTER=<ID=str_contraction,Description=\"Site filtered due to contraction of short tandem repeat region\">\n",
    "* FILTER=<ID=strand_artifact,Description=\"Evidence for alt allele comes from one read direction only\">\n",
    "* FILTER=<ID=t_lod_fstar,Description=\"Tumor does not meet likelihood threshold\">\n",
    "* FILTER=<ID=triallelic_site,Description=\"Site filtered because more than two alt alleles pass tumor LOD\">\n",
    "* FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">\n",
    "* FORMAT=<ID=AF,Number=1,Type=Float,Description=\"Allele fraction of the event in the tumor\">\n",
    "* FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth (reads with MQ=255 or with bad mates are filtered)\">\n",
    "* FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality\">\n",
    "* FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
    "* FORMAT=<ID=PGT,Number=1,Type=String,Description=\"Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another\">\n",
    "* FORMAT=<ID=PID,Number=1,Type=String,Description=\"Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group\">\n",
    "* FORMAT=<ID=PL,Number=G,Type=Integer,Description=\"Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification\">\n",
    "* INFO=<ID=ClippingRankSum,Number=1,Type=Float,Description=\"Z-score From Wilcoxon rank sum test of Alt vs. Ref number of hard clipped bases\">\n",
    "* INFO=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth; some reads may have been filtered\">\n",
    "* INFO=<ID=ECNT,Number=1,Type=String,Description=\"Number of events in this haplotype\">\n",
    "* INFO=<ID=FS,Number=1,Type=Float,Description=\"Phred-scaled p-value using Fisher's exact test to detect strand bias\">\n",
    "* INFO=<ID=GC,Number=1,Type=Float,Description=\"GC content around the variant (see docs for window size details)\">\n",
    "* INFO=<ID=HCNT,Number=1,Type=String,Description=\"Number of haplotypes that support this variant\">\n",
    "* INFO=<ID=HRun,Number=1,Type=Integer,Description=\"Largest Contiguous Homopolymer Run of Variant Allele In Either Direction\">\n",
    "* INFO=<ID=HaplotypeScore,Number=1,Type=Float,Description=\"Consistency of the site with at most two segregating haplotypes\">\n",
    "* INFO=<ID=MAX_ED,Number=1,Type=Integer,Description=\"Maximum distance between events in this active region\">\n",
    "* INFO=<ID=MIN_ED,Number=1,Type=Integer,Description=\"Minimum distance between events in this active region\">\n",
    "* INFO=<ID=MQ,Number=1,Type=Float,Description=\"RMS Mapping Quality\">\n",
    "* INFO=<ID=MQ0,Number=1,Type=Integer,Description=\"Total Mapping Quality Zero Reads\">\n",
    "* INFO=<ID=MQRankSum,Number=1,Type=Float,Description=\"Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities\">\n",
    "* INFO=<ID=NLOD,Number=1,Type=String,Description=\"Normal LOD score\">\n",
    "* INFO=<ID=PON,Number=1,Type=String,Description=\"Count from Panel of Normals\">\n",
    "* INFO=<ID=QD,Number=1,Type=Float,Description=\"Variant Confidence/Quality by Depth\">\n",
    "* INFO=<ID=ReadPosRankSum,Number=1,Type=Float,Description=\"Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias\">\n",
    "* INFO=<ID=TLOD,Number=1,Type=String,Description=\"Tumor LOD score\">\n",
    "\n",
    "#### Vardict\n",
    "* FILTER=<ID=PASS,Description=\"All filters passed\">\n",
    "* FILTER=<ID=Bias,Description=\"Strand Bias\">\n",
    "* FILTER=<ID=Cluster0bp,Description=\"Two somatic variants are within 0 bp\">\n",
    "* FILTER=<ID=DIFF0.2,Description=\"Non-somatic or LOH and allele frequency difference < 0.2\">\n",
    "* FILTER=<ID=InDelLikely,Description=\"Likely Indels are not considered somatic\">\n",
    "* FILTER=<ID=InGap,Description=\"The somatic variant is in the deletion gap, thus likely false positive\">\n",
    "* FILTER=<ID=InIns,Description=\"The somatic variant is adjacent to an insertion variant\">\n",
    "* FILTER=<ID=LongAT,Description=\"The somatic variant is flanked by long A/T (>=14)\">\n",
    "* FILTER=<ID=LowAlleleDepth,Description=\"Low depth per allele frequency along with poor depth, quality, mapping quality and read mismatches.\">\n",
    "* FILTER=<ID=LowFreqQuality,Description=\"Low frequency read with poor quality and p-value (SSF).\">\n",
    "* FILTER=<ID=MAF0.05,Description=\"Matched sample has AF > 0.05, thus not somatic\">\n",
    "* FILTER=<ID=MSI12,Description=\"Variant in MSI region with 12 non-monomer MSI or 12 monomer MSI\">\n",
    "* FILTER=<ID=NM4.25,Description=\"Mean mismatches in reads >= 4.25, thus likely false positive\">\n",
    "* FILTER=<ID=P0.01Likely,Description=\"Likely candidate but p-value > 0.01/5**vd2\">\n",
    "* FILTER=<ID=P0.9,Description=\"Not significant with p-value > 0.9\">\n",
    "* FILTER=<ID=Q0,Description=\"Mean Mapping Quality Below 0\">\n",
    "* FILTER=<ID=REJECT,Description=\"Not Somatic via VarDict\">\n",
    "* FILTER=<ID=SN1.5,Description=\"Signal to Noise Less than 1.5\">\n",
    "* FILTER=<ID=d5,Description=\"Total Depth < 5\">\n",
    "* FILTER=<ID=f0.1,Description=\"Allele frequency < 0.1\">\n",
    "* FILTER=<ID=p8,Description=\"Mean Position in Reads Less than 8\">\n",
    "* FILTER=<ID=pSTD,Description=\"Position in Reads has STD of 0\">\n",
    "* FILTER=<ID=q22.5,Description=\"Mean Base Quality Below 22.5\">\n",
    "* FILTER=<ID=v3,Description=\"Var Depth < 3\">\n",
    "* FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">\n",
    "* FORMAT=<ID=ADJAF,Number=1,Type=Float,Description=\"Adjusted AF for indels due to local realignment\">\n",
    "* FORMAT=<ID=AF,Number=1,Type=Float,Description=\"Allele Frequency\">\n",
    "* FORMAT=<ID=ALD,Number=2,Type=Integer,Description=\"Variant forward, reverse reads\">\n",
    "* FORMAT=<ID=BIAS,Number=1,Type=String,Description=\"Strand Bias Info\">\n",
    "* FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Total Depth\">\n",
    "* FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
    "* FORMAT=<ID=HIAF,Number=1,Type=Float,Description=\"Allele frequency using only high quality bases\">\n",
    "* FORMAT=<ID=MQ,Number=1,Type=Float,Description=\"Mean Mapping Quality\">\n",
    "* FORMAT=<ID=NM,Number=1,Type=Float,Description=\"Mean mismatches in reads\">\n",
    "* FORMAT=<ID=ODDRATIO,Number=1,Type=Float,Description=\"Strand Bias Odds ratio\">\n",
    "* FORMAT=<ID=PMEAN,Number=1,Type=Float,Description=\"Mean position in reads\">\n",
    "* FORMAT=<ID=PSTD,Number=1,Type=Float,Description=\"Position STD in reads\">\n",
    "* FORMAT=<ID=QSTD,Number=1,Type=Float,Description=\"Quality score STD in reads\">\n",
    "* FORMAT=<ID=QUAL,Number=1,Type=Float,Description=\"Mean quality score in reads\">\n",
    "* FORMAT=<ID=RD,Number=2,Type=Integer,Description=\"Reference forward, reverse reads\">\n",
    "* FORMAT=<ID=SBF,Number=1,Type=Float,Description=\"Strand Bias Fisher p-value\">\n",
    "* FORMAT=<ID=SN,Number=1,Type=Float,Description=\"Signal to noise\">\n",
    "* FORMAT=<ID=VD,Number=1,Type=Integer,Description=\"Variant Depth\">\n",
    "* INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele Frequency, for each ALT allele, in the same order as listed\">\n",
    "* INFO=<ID=DP,Number=1,Type=Integer,Description=\"Total Depth\">\n",
    "* INFO=<ID=END,Number=1,Type=Integer,Description=\"Chr End Position\">\n",
    "* INFO=<ID=LSEQ,Number=1,Type=String,Description=\"5' flanking seq\">\n",
    "* INFO=<ID=MSI,Number=1,Type=Float,Description=\"MicroSatellite. > 1 indicates MSI\">\n",
    "* INFO=<ID=MSILEN,Number=1,Type=Float,Description=\"MSI unit repeat length in bp\">\n",
    "* INFO=<ID=RSEQ,Number=1,Type=String,Description=\"3' flanking seq\">\n",
    "* INFO=<ID=SAMPLE,Number=1,Type=String,Description=\"Sample name (with whitespace translated to underscores)\">\n",
    "* INFO=<ID=SHIFT3,Number=1,Type=Integer,Description=\"No. of bases to be shifted to 3 prime for deletions due to alternative alignment\">\n",
    "* INFO=<ID=SOMATIC,Number=0,Type=Flag,Description=\"Somatic event\">\n",
    "* INFO=<ID=SOR,Number=1,Type=Float,Description=\"Odds ratio\">\n",
    "* INFO=<ID=SSF,Number=1,Type=Float,Description=\"P-value\">\n",
    "* INFO=<ID=STATUS,Number=1,Type=String,Description=\"Somatic or germline status\">\n",
    "* INFO=<ID=TYPE,Number=1,Type=String,Description=\"Variant Type: SNV Insertion Deletion Complex\">\n",
    "* INFO=<ID=VD,Number=1,Type=Integer,Description=\"Variant Depth\">\n",
    "\n",
    "#### Varscan\n",
    "* FILTER=<ID=PASS,Description=\"All filters passed\">\n",
    "* FILTER=<ID=REJECT,Description=\"Set if true: SS != '.' && SS != '2'\">\n",
    "* FILTER=<ID=SpvFreq,Description=\"High frequency (tumor FREQ > 0.35) and low p-value for somatic (SPV < 0.05)\">\n",
    "* FILTER=<ID=indelError,Description=\"Likely artifact due to indel reads at this position\">\n",
    "* FILTER=<ID=str10,Description=\"Less than 10% or more than 90% of variant supporting reads on one strand\">\n",
    "* FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">\n",
    "* FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read Depth\">\n",
    "* FORMAT=<ID=DP4,Number=1,Type=String,Description=\"Strand read counts: ref/fwd, ref/rev, var/fwd, var/rev\">\n",
    "* FORMAT=<ID=FREQ,Number=1,Type=Float,Description=\"Variant allele frequency\">\n",
    "* FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality\">\n",
    "* FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
    "* FORMAT=<ID=RD,Number=1,Type=Integer,Description=\"Depth of reference-supporting bases (reads1)\">\n",
    "* INFO=<ID=DP,Number=1,Type=Integer,Description=\"Total depth of quality bases\">\n",
    "* INFO=<ID=GPV,Number=1,Type=Float,Description=\"Fisher's Exact Test P-value of tumor+normal versus no variant for Germline calls\">\n",
    "* INFO=<ID=SOMATIC,Number=0,Type=Flag,Description=\"Indicates if record is a somatic mutation\">\n",
    "* INFO=<ID=SPV,Number=1,Type=Float,Description=\"Fisher's Exact Test P-value of tumor versus normal for Somatic/LOH calls\">\n",
    "* INFO=<ID=SS,Number=1,Type=String,Description=\"Somatic status of variant (0=Reference,1=Germline,2=Somatic,3=LOH, or 5=Unknown)\">\n",
    "* INFO=<ID=SSC,Number=1,Type=Float,Description=\"Somatic score in Phred scale (0-255) derived from somatic p-value\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['ID_freebayes','ID_mutect2','ID_vardict','ID_varscan', # id\n",
    "                 'REF_freebayes','REF_mutect2','REF_vardict','REF_varscan', # ref genome\n",
    "                 'ALT_1_freebayes','ALT_1_mutect2','ALT_1_vardict','ALT_1_varscan',\n",
    "                 'ANN_freebayes','ANN_mutect2','ANN_vardict','ANN_varscan',\n",
    "                 'LSEQ_vardict','RSEQ_vardict','SAMPLE_vardict','STATUS_vardict',\n",
    "                 'TYPE_1_freebayes','TYPE_vardict', # type of mutation\n",
    "                 'CIGAR_1_freebayes'] # only one value (\"1X\") found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Decision Trees\n",
    "* popular algorithms like XGboost and Catboost are examples of using the gradient boosting framework \n",
    "* unlike random forests, the decision trees in gradient boosting are built additively; each decision tree is built one after another\n",
    "* each new tree is built to improve on deficiencies of the previous trees and this concept is called boosting \n",
    "* gradient of gradient boosting comes from minimising the gradient of the loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from numpy import nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[          CHROM     POS REF_vs  ALT_1_vs  SSC_vs    SPV_vs  is_snp_vs\n",
       " 0             1   10146     AC       NaN     2.0  0.568070      False\n",
       " 1             1   10177      A       NaN     8.0  0.129110      False\n",
       " 2             1   10230     AC       NaN     4.0  0.361360      False\n",
       " 3             1   10247      T       NaN    11.0  0.070191       True\n",
       " 4             1   10248      A       NaN     8.0  0.152890       True\n",
       " ..          ...     ...    ...       ...     ...       ...        ...\n",
       " 229  GL000192.1  546648      C       NaN     0.0  0.896130       True\n",
       " 230  GL000192.1  547087      T       NaN     4.0  0.376560       True\n",
       " 231  GL000192.1  547102      C       NaN     1.0  0.728090       True\n",
       " 232  GL000192.1  547218      C       NaN     3.0  0.469670       True\n",
       " 233  GL000192.1  547406      G       NaN     2.0  0.520770       True\n",
       " \n",
       " [4718826 rows x 7 columns],\n",
       "             CHROM     POS REF_fb  ALT_1_fb    MQMR_fb  is_snp_fb\n",
       " 0               1   10352      T       NaN        NaN      False\n",
       " 1               1   10583      G       NaN  41.000000       True\n",
       " 2               1   12783      G       NaN  23.761900       True\n",
       " 3               1   13550      G       NaN  23.341499       True\n",
       " 4               1   13668      G       NaN  17.242399       True\n",
       " ...           ...     ...    ...       ...        ...        ...\n",
       " 25894  GL000192.1  545445      A       NaN  55.328400       True\n",
       " 25895  GL000192.1  545485      A       NaN  56.817200       True\n",
       " 25896  GL000192.1  546636      G       NaN  31.688299       True\n",
       " 25897  GL000192.1  546648      C       NaN  32.120899       True\n",
       " 25898  GL000192.1  547218      C       NaN  47.294102       True\n",
       " \n",
       " [4744491 rows x 6 columns],\n",
       "             CHROM     POS REF_m2  ALT_1_m2  mQ_m2  is_snp_m2\n",
       " 0               1   13079      C       NaN    NaN       True\n",
       " 1               1   14653      C       NaN    NaN       True\n",
       " 2               1   16125      T       NaN    NaN       True\n",
       " 3               1   16288      C       NaN    NaN       True\n",
       " 4               1   16737      G       NaN    NaN       True\n",
       " ...           ...     ...    ...       ...    ...        ...\n",
       " 41583  GL000192.1  482874      G       NaN    NaN       True\n",
       " 41584  GL000192.1  482922  GAAAT       NaN    NaN      False\n",
       " 41585  GL000192.1  523933      C       NaN    NaN      False\n",
       " 41586  GL000192.1  524358      A       NaN    NaN       True\n",
       " 41587  GL000192.1  534759      G       NaN    NaN       True\n",
       " \n",
       " [107124 rows x 6 columns],\n",
       "             CHROM     POS REF_vd  ALT_1_vd   SSF_vd  MSI_vd  is_snp_vd\n",
       " 0               1   10180      T       NaN  0.07787     2.0       True\n",
       " 1               1   10230     AC       NaN  0.30777    11.0      False\n",
       " 2               1   10254     TA       NaN  0.00322     3.0      False\n",
       " 3               1   10329     AC       NaN  0.54830     4.0      False\n",
       " 4               1   10352      T       NaN  0.15040     3.0      False\n",
       " ...           ...     ...    ...       ...      ...     ...        ...\n",
       " 59662  GL000192.1  545628   GTTC       NaN  0.51165     2.0      False\n",
       " 59663  GL000192.1  545721      G       NaN  0.49600     2.0       True\n",
       " 59664  GL000192.1  546636      G       NaN  0.30532     5.0       True\n",
       " 59665  GL000192.1  546648      C       NaN  0.31331     3.0       True\n",
       " 59666  GL000192.1  547218      C       NaN  0.24814     3.0       True\n",
       " \n",
       " [4778259 rows x 7 columns]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This part has been incorporated into parsing code\n",
    "lst_dfs = [varscan_sub,freebayes_sub,mutect2_sub,vardict_sub]\n",
    "suffix = ['vs','fb','m2','vd']\n",
    "keep_same = {'CHROM', 'POS'}\n",
    "i =0 \n",
    "for df in lst_dfs:\n",
    "    df.columns = ['{}{}'.format(c, '' if c in keep_same else '_'+suffix[i]) for c in df.columns]\n",
    "    i += 1\n",
    "lst_dfs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This part has been incorporated into parsing code\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right,on =['CHROM', 'POS'],\n",
    "                                            how = 'outer', suffixes = ('', '')),lst_dfs)\n",
    "'''\n",
    "\n",
    "algos = ['freebayes', 'mutect2', 'vardict', 'varscan']\n",
    "merged_df = merged_df.drop([f'is_snp_{algo}' for algo in algos], axis=1)\n",
    "#merged_df.to_csv(\"syn1_mergered_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import xgboost as xgb \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\n"
     ]
    }
   ],
   "source": [
    "##  function to get y labels\n",
    "truth_labels = pd.read_csv(\"syn1/syn1_truth.bed\", sep = \"\\t\", names = ['Chromo', 'start', 'end'])\n",
    "print(list(set(truth_labels.start == truth_labels.end) )) # the start and end position are the same \n",
    "truth_labels = truth_labels[['Chromo', 'start']]\n",
    "truth_labels['truth'] = 1\n",
    "sub_truth= truth_labels.rename(columns = {'Chromo':'CHROM', 'start':'POS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dataset \n",
    "combined = merged_df.merge(sub_truth, on=['CHROM','POS'], how = 'left' )\n",
    "combined['truth'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined[combined.columns[~combined.columns.isin(['truth','POS','CHROM'])]]\n",
    "\n",
    "y = combined['truth'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encoding for REF and ALT\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(X)\n",
    "new_X = enc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(eval_metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='rmse', feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='mlogloss', feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=None, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=16, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
    "              gamma=0, gpu_id=-1, importance_type='gain',\n",
    "              interaction_constraints='', learning_rate=0.300000012,\n",
    "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
    "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
    "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[926684     45]\n",
      " [    45    664]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    926729\n",
      "         1.0       0.94      0.94      0.94       709\n",
      "\n",
      "    accuracy                           1.00    927438\n",
      "   macro avg       0.97      0.97      0.97    927438\n",
      "weighted avg       1.00      1.00      1.00    927438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance # for syn1 dataset \n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[930908     27]\n",
      " [    42    227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    930935\n",
      "         1.0       0.89      0.84      0.87       269\n",
      "\n",
      "    accuracy                           1.00    931204\n",
      "   macro avg       0.95      0.92      0.93    931204\n",
      "weighted avg       1.00      1.00      1.00    931204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance # for real1 dataset \n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca047435e123f1adf8ceaa4e29276b42b8cdbe924d11fa9449688af84adf0afc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
