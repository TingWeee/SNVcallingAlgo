{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place the python file in the same folder containing all the real1, real2_part1, ... folders\n",
    "\n",
    "def parse_to_df(folder='test', features='*', algos=['freebayes', 'mutect2', 'vardict', 'varscan']):\n",
    "    '''\n",
    "    reads all vcf.gz files corresponding to algos in the specified folder with the specified list of features\n",
    "    and combines the read files into one dataframe with (CHROM, POS, REF) as index.\n",
    "    '''\n",
    "    if folder == 'test':\n",
    "        dfs = [allel.vcf_to_dataframe(f'{folder}/{i}.vcf.gz', fields = features) for i in algos]\n",
    "    else:\n",
    "        dfs = [allel.vcf_to_dataframe(f'{folder}/{folder}-{i}.vcf.gz', fields = features) for i in algos]\n",
    "    algo_dicts = dict(zip(algos, dfs))\n",
    "    \n",
    "    #some manipulations\n",
    "    for i in algo_dicts:\n",
    "        algo_dicts[i].set_index(keys=['CHROM', 'POS', 'REF'], inplace = True) #will be use as keys for later merging\n",
    "        algo_dicts[i] = algo_dicts[i][algo_dicts[i]['is_snp']]    #obtain only SNPs\n",
    "        algo_dicts[i].columns = [j + '_' + i for j in algo_dicts[i].columns]\n",
    "\n",
    "    #combining the dfs\n",
    "    edited_dfs = [algo_dicts[i] for i in algos]\n",
    "\n",
    "    merged = reduce(lambda left, right: pd.merge(left, right,\n",
    "                                            how = 'outer',\n",
    "                                            left_index=True, right_index=True,\n",
    "                                            suffixes = ('', '')), edited_dfs)\n",
    "\n",
    "    merged.columns = sorted(merged.columns)\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/opt/anaconda3/lib/python3.9/site-packages/allel/io/vcf_read.py:1240: UserWarning: 'ALT_1' INFO header not found\n",
      "  warnings.warn('%r INFO header not found' % name)\n",
      "/Users/ting/opt/anaconda3/lib/python3.9/site-packages/allel/io/vcf_read.py:1454: UserWarning: no type for field 'variants/ALT_1', assuming object\n",
      "  warnings.warn('no type for field %r, assuming %s' % (f, normed_types[f]))\n",
      "/Users/ting/opt/anaconda3/lib/python3.9/site-packages/allel/io/vcf_read.py:1564: UserWarning: no number for field 'variants/ALT_1', assuming 1\n",
      "  warnings.warn('no number for field %r, assuming 1' % f)\n",
      "/Users/ting/opt/anaconda3/lib/python3.9/site-packages/allel/io/vcf_read.py:1240: UserWarning: 'mQ' INFO header not found\n",
      "  warnings.warn('%r INFO header not found' % name)\n",
      "/Users/ting/opt/anaconda3/lib/python3.9/site-packages/allel/io/vcf_read.py:1454: UserWarning: no type for field 'variants/mQ', assuming object\n",
      "  warnings.warn('no type for field %r, assuming %s' % (f, normed_types[f]))\n",
      "/Users/ting/opt/anaconda3/lib/python3.9/site-packages/allel/io/vcf_read.py:1564: UserWarning: no number for field 'variants/mQ', assuming 1\n",
      "  warnings.warn('no number for field %r, assuming 1' % f)\n"
     ]
    }
   ],
   "source": [
    "# parse_to_df function takes too long to run so I parse individually \n",
    "# try with rand subset of features \n",
    "varscan_features = ['CHROM','POS','REF','ALT_1', 'SSC','SPV','is_snp']\n",
    "real1_varscan_sub = allel.vcf_to_dataframe(\"syn1/syn1-varscan.vcf.gz\", fields = varscan_features)\n",
    "\n",
    "freebayes_features = ['CHROM','POS','REF','ALT_1', 'MQMR','is_snp']\n",
    "real1_freebayes_sub = allel.vcf_to_dataframe(\"syn1/syn1-freebayes.vcf.gz\", fields = freebayes_features)\n",
    "\n",
    "mutect2_features = ['CHROM','POS','REF','ALT_1', 'mQ','is_snp']\n",
    "real1_mutect2_sub = allel.vcf_to_dataframe(\"syn1/syn1-mutect2.vcf.gz\", fields = mutect2_features)\n",
    "\n",
    "vardict_features = ['CHROM','POS','REF','ALT_1', 'SSF','MSI','is_snp']\n",
    "real1_vardict_sub = allel.vcf_to_dataframe(\"syn1/syn1-vardict.vcf.gz\", fields = vardict_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting for snp = True \n",
    "varscan_sub = real1_varscan_sub[real1_varscan_sub.is_snp == True]\n",
    "freebayes_sub = real1_freebayes_sub[real1_freebayes_sub.is_snp == True]\n",
    "mutect2_sub = real1_mutect2_sub[real1_mutect2_sub.is_snp == True]\n",
    "vardict_sub = real1_vardict_sub[real1_vardict_sub.is_snp == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Decision Trees\n",
    "# popular algorithms like XGboost and Catboost are examples of using the gradient boosting framework \n",
    "# unlike random forests, the decision trees in gradient boosting are built additively; each decision tree is built one after another\n",
    "# each new treee is built to improve on deficiencies of the previous trees and this concept is called boosting \n",
    "# gradient of gradient boosting comes from minimising the gradient of the loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from numpy import nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[          CHROM     POS REF_vs  ALT_1_vs  SSC_vs    SPV_vs  is_snp_vs\n",
       " 3             1   10247      T       NaN    11.0  0.070191       True\n",
       " 4             1   10248      A       NaN     8.0  0.152890       True\n",
       " 6             1   10257      A       NaN    11.0  0.068939       True\n",
       " 11            1   12783      G       NaN    16.0  0.024513       True\n",
       " 12            1   12807      C       NaN     6.0  0.239270       True\n",
       " ..          ...     ...    ...       ...     ...       ...        ...\n",
       " 229  GL000192.1  546648      C       NaN     0.0  0.896130       True\n",
       " 230  GL000192.1  547087      T       NaN     4.0  0.376560       True\n",
       " 231  GL000192.1  547102      C       NaN     1.0  0.728090       True\n",
       " 232  GL000192.1  547218      C       NaN     3.0  0.469670       True\n",
       " 233  GL000192.1  547406      G       NaN     2.0  0.520770       True\n",
       " \n",
       " [4119533 rows x 7 columns],\n",
       "             CHROM     POS REF_fb  ALT_1_fb    MQMR_fb  is_snp_fb\n",
       " 1               1   10583      G       NaN  41.000000       True\n",
       " 2               1   12783      G       NaN  23.761900       True\n",
       " 3               1   13550      G       NaN  23.341499       True\n",
       " 4               1   13668      G       NaN  17.242399       True\n",
       " 5               1   13868      A       NaN  19.818199       True\n",
       " ...           ...     ...    ...       ...        ...        ...\n",
       " 25894  GL000192.1  545445      A       NaN  55.328400       True\n",
       " 25895  GL000192.1  545485      A       NaN  56.817200       True\n",
       " 25896  GL000192.1  546636      G       NaN  31.688299       True\n",
       " 25897  GL000192.1  546648      C       NaN  32.120899       True\n",
       " 25898  GL000192.1  547218      C       NaN  47.294102       True\n",
       " \n",
       " [4021700 rows x 6 columns],\n",
       "             CHROM     POS REF_m2  ALT_1_m2  mQ_m2  is_snp_m2\n",
       " 0               1   13079      C       NaN    NaN       True\n",
       " 1               1   14653      C       NaN    NaN       True\n",
       " 2               1   16125      T       NaN    NaN       True\n",
       " 3               1   16288      C       NaN    NaN       True\n",
       " 4               1   16737      G       NaN    NaN       True\n",
       " ...           ...     ...    ...       ...    ...        ...\n",
       " 41581  GL000192.1  482860      G       NaN    NaN       True\n",
       " 41582  GL000192.1  482864      G       NaN    NaN       True\n",
       " 41583  GL000192.1  482874      G       NaN    NaN       True\n",
       " 41586  GL000192.1  524358      A       NaN    NaN       True\n",
       " 41587  GL000192.1  534759      G       NaN    NaN       True\n",
       " \n",
       " [94180 rows x 6 columns],\n",
       "             CHROM     POS REF_vd  ALT_1_vd   SSF_vd  MSI_vd  is_snp_vd\n",
       " 0               1   10180      T       NaN  0.07787     2.0       True\n",
       " 5               1   10443      C       NaN  0.13320     1.0       True\n",
       " 6               1   10583      G       NaN  0.50000     1.0       True\n",
       " 7               1   12783      G       NaN  0.60162     1.0       True\n",
       " 8               1   12807      C       NaN  0.39717     1.0       True\n",
       " ...           ...     ...    ...       ...      ...     ...        ...\n",
       " 59661  GL000192.1  545485      A       NaN  0.53622     1.0       True\n",
       " 59663  GL000192.1  545721      G       NaN  0.49600     2.0       True\n",
       " 59664  GL000192.1  546636      G       NaN  0.30532     5.0       True\n",
       " 59665  GL000192.1  546648      C       NaN  0.31331     3.0       True\n",
       " 59666  GL000192.1  547218      C       NaN  0.24814     3.0       True\n",
       " \n",
       " [4038752 rows x 7 columns]]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_dfs = [varscan_sub,freebayes_sub,mutect2_sub,vardict_sub]\n",
    "suffix = ['vs','fb','m2','vd']\n",
    "keep_same = {'CHROM', 'POS'}\n",
    "i =0 \n",
    "for df in lst_dfs:\n",
    "    df.columns = ['{}{}'.format(c, '' if c in keep_same else '_'+suffix[i]) for c in df.columns]\n",
    "    i += 1\n",
    "lst_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = reduce(lambda left, right: pd.merge(left, right,on =['CHROM', 'POS'],\n",
    "                                            how = 'outer', suffixes = ('', '')),lst_dfs)\n",
    "merged_df = merged_df.drop(['is_snp_vd','is_snp_fb','is_snp_m2','is_snp_vs'], axis=1)\n",
    "merged_df.to_csv(\"syn1_mergered_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import xgboost as xgb \n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\n"
     ]
    }
   ],
   "source": [
    "##  function to get y labels\n",
    "truth_labels = pd.read_csv(\"syn1/syn1_truth.bed\", sep = \"\\t\", names = ['Chromo', 'start', 'end'])\n",
    "print(list(set(truth_labels.start == truth_labels.end) )) # the start and end position are the same \n",
    "truth_labels = truth_labels[['Chromo', 'start']]\n",
    "truth_labels['truth'] = 1\n",
    "sub_truth= truth_labels.rename(columns = {'Chromo':'CHROM', 'start':'POS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dataset \n",
    "combined = merged_df.merge(sub_truth, on=['CHROM','POS'], how = 'left' )\n",
    "combined['truth'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined[combined.columns[~combined.columns.isin(['truth','POS','CHROM'])]]\n",
    "\n",
    "y = combined['truth'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encoding for REF and ALT\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(X)\n",
    "new_X = enc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(eval_metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='rmse', feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='mlogloss', feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=None, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=16, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
    "              gamma=0, gpu_id=-1, importance_type='gain',\n",
    "              interaction_constraints='', learning_rate=0.300000012,\n",
    "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
    "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
    "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[926684     45]\n",
      " [    45    664]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    926729\n",
      "         1.0       0.94      0.94      0.94       709\n",
      "\n",
      "    accuracy                           1.00    927438\n",
      "   macro avg       0.97      0.97      0.97    927438\n",
      "weighted avg       1.00      1.00      1.00    927438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance # for syn1 dataset \n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[930908     27]\n",
      " [    42    227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    930935\n",
      "         1.0       0.89      0.84      0.87       269\n",
      "\n",
      "    accuracy                           1.00    931204\n",
      "   macro avg       0.95      0.92      0.93    931204\n",
      "weighted avg       1.00      1.00      1.00    931204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance # for real1 dataset \n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca047435e123f1adf8ceaa4e29276b42b8cdbe924d11fa9449688af84adf0afc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
